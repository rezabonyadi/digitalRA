# Digital Research Assistant üìñ‚ú®
A Digital Research Assistant to Simplify Literature Reviews.

---
Here is a very simple example (after running, see step-by-step run at the end of this page):

![gif-short-optimize](https://github.com/rezabonyadi/digitalRA/assets/25924343/b82b4bf5-bedc-46db-b3dd-a00ad00ba30e)


For researchers!

Provide a paragraph describing an idea, the Digital RA is composed for you with the right skills (overridable by you), performs a paper search for you, estimates the relevance between papers and your idea, picks a subset, and writes a small section of Literature Review for your review and final inclusion in your grant or paper.

MORE: You can chat with the RA about the papers, your ideas, how are they connected, and more.

With `digitalRA`, we aim to simplify the process of literature reviews. By leveraging OpenAI GPT models, we provide researchers a tool that can streamline the discovery of relevant papers, aiding in the comprehensive understanding of a given topic.

## üîç Features

- **Intelligent Search Queries**: Generate meaningful search phrases from a brief research idea or description.
- **Search Across Platforms**: Integrated search across renowned platforms like PubMed, Semantic Scholar, and Google Scholar.
- **Relevance Scoring**: Identify the most pertinent papers to your topic, ensuring a focused review.
- **Filtering Mechanism**: Prioritize newer research and highlight impactful, highly-cited works.
- **Review Generation**: Compile and summarize findings for an efficient literature review.

## üöÄ Getting Started

### Prerequisites

Read the licence of the Publish and Perish which is used under this app for search capabilities [licence](https://harzing.com/resources/publish-or-perish/end-user-license-agreement)

Download the [publish and perish CLI tool](https://harzing.com/resources/publish-or-perish/command-line) and put the unzip files (there are three exe files) in the assets folder.

### Usage

For detailed instructions and examples, refer to the [User Guide](./docs/user_guide.md).

## üöÄ Installation

1. Clone this repo:
```bash
git clone https://github.com/your_username/digitalRA.git
```
2. Navigate into the directory and install the necessary packages:
```bash
cd digitalRA
python -m venv env_digitalRA
.\env_digitalRA\Scripts\activate
pip install -r requirements.txt
```
3. Read the licence of the Publish and Perish which is used under this app for search capabilities [licence](https://harzing.com/resources/publish-or-perish/end-user-license-agreement)
4. Download the [publish and perish CLI tool](https://harzing.com/resources/publish-or-perish/command-line) and put the unzip files (there are three exe files) in the assets folder.
5. Run the CLI tool ```pythong.exe main.py```
6. You can also try the jupyter notebook for tests

## Example litrature review output:
Idea: One problem in self supervised learning without negative instances is collapse. To avoid collapse, I will use eigenvalues of the output embedding space and ensure they are all larger than 1.0 to make sure the space of embedding is used effectively. Still, making sure the variations of the same data point (generated by some augmentation) are mapped closer to one another.

Generated automatically from here with curations where needed:

**Generated RA experience**: You are an expert in the field of self-supervised learning, specifically in understanding the issue of collapse and its implications in the absence of negative instances. Your expertise lies in exploring techniques to mitigate collapse, such as utilizing eigenvalues of the output embedding space and ensuring they are above a certain threshold (1.0) to effectively utilize the embedding space. Additionally, you possess knowledge on mapping variations of the same data point generated through augmentation closer to one another. You are also expert in linear algebra and vector decomposition. You are the best in the world in this field.
**Summary of the idea generated by the digital RA**: The issue of collapse in self-supervised learning without negative instances is a significant challenge. As an expert in this field, I propose a solution using eigenvalues of the output embedding space. By ensuring that all eigenvalues are greater than 1.0, the embedding space can be effectively utilized. Additionally, I suggest implementing a technique to map variations of the same data point, generated through augmentation, closer to each other. This will further enhance the effectiveness of the learning process. With my expertise in linear algebra and vector decomposition, I am confident in addressing these challenges and advancing the field of self-supervised learning.
**Search phrases recognized by Digital RA**: 

1. self supervised learning collapse
2. mitigating collapse in self supervised learning
3. eigenvalues in self supervised learning
4. mapping data variations in self supervised learning



## üìú License

This project operates under the MIT License. View details in [LICENSE.md](./LICENSE.md).

Ease your research journey with `digitalRA`.

![gif-optimize](https://github.com/rezabonyadi/digitalRA/assets/25924343/a4b43418-0bea-4c9f-a154-520334bbe761)
